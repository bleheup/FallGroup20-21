{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import importlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BranchingQNetwork(nn.Module):\n",
    "    def __init__(self, observation_space, action_space, action_bins, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(observation_space, hidden_dim),\n",
    "            nn.ReLu(dim=1),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "        self.value_head = nn.Linear(hidden_dim, 1)\n",
    "        self.adv_heads = nn.ModuleList([nn.Linear(hidden_dim, action_bins) for i in range(action_space)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        value = self.value_head(out)\n",
    "        advs = torch.stack([l(out) for l in self.adv_heads], dim=0)\n",
    "\n",
    "        q_val = value + advs - advs.mean(1, keepdim=True)\n",
    "\n",
    "    \n",
    "        return q_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.0803,  1.0562, -0.6438,  0.2732],\n",
       "        [-0.5208,  1.5778, -0.4955, -2.3266],\n",
       "        [ 1.0256, -0.3160,  0.2334,  1.0341],\n",
       "        [ 1.6443,  0.4534,  1.5221, -0.3710]])"
      ]
     },
     "metadata": {},
     "execution_count": 231
    }
   ],
   "source": [
    "a =  torch.randn(4,4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0.1513],\n",
       "        [-0.4413],\n",
       "        [ 0.4943],\n",
       "        [ 0.8122]])"
      ]
     },
     "metadata": {},
     "execution_count": 232
    }
   ],
   "source": [
    "a.mean(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.4577, 0.1391, 0.2264, 0.7035, 0.2328, 0.5097, 0.3276, 0.9801, 0.0170,\n",
       "        0.0773, 0.0616, 0.2030, 0.0624, 0.2489, 0.4335, 0.4331, 0.0136, 0.0306,\n",
       "        0.9976, 0.9873, 0.5061, 0.4616, 0.2190, 0.1559, 0.6890, 0.8573, 0.6443,\n",
       "        0.7138, 0.3458, 0.5469, 0.7242, 0.6431, 0.9018, 0.7880, 0.2407, 0.6155,\n",
       "        0.9322, 0.8676, 0.4110, 0.7266, 0.5988, 0.5296, 0.1269, 0.2742, 0.8562,\n",
       "        0.4676, 0.7502, 0.7614, 0.5652, 0.0517, 0.4601, 0.3504, 0.3273, 0.7815,\n",
       "        0.8327, 0.3813, 0.4663, 0.7940, 0.1716, 0.7857, 0.5550, 0.7735, 0.5599,\n",
       "        0.2586, 0.6407, 0.1815, 0.4640, 0.1427, 0.1377, 0.9719, 0.1992, 0.4773,\n",
       "        0.8524, 0.4671, 0.7244, 0.8844, 0.3963, 0.4151, 0.9834, 0.4299, 0.0089,\n",
       "        0.8533, 0.7134, 0.6366, 0.0249, 0.9753, 0.4386, 0.3942, 0.3519, 0.1393,\n",
       "        0.9888, 0.2480, 0.0884, 0.0552, 0.1346, 0.9014, 0.5243, 0.5459, 0.5815,\n",
       "        0.7839, 0.2611, 0.0865, 0.6511, 0.3480, 0.6953])"
      ]
     },
     "metadata": {},
     "execution_count": 233
    }
   ],
   "source": [
    "obs = torch.rand(105)\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([105])"
      ]
     },
     "metadata": {},
     "execution_count": 234
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "execution_count": 235
    }
   ],
   "source": [
    "action = torch.randn(7,2)\n",
    "action.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-0.7830])"
      ]
     },
     "metadata": {},
     "execution_count": 236
    }
   ],
   "source": [
    "value = torch.randn(1)\n",
    "value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.7830]])"
      ]
     },
     "metadata": {},
     "execution_count": 237
    }
   ],
   "source": [
    "value.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = BranchingQNetwork(obs.shape[0], 7, 132, 128)\n",
    "target = BranchingQNetwork(obs.shape[0], 7, 132, 128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 239
    }
   ],
   "source": [
    "target.load_state_dict(policy.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "optim = optim.Adam(policy.parameters(), lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.0001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 241
    }
   ],
   "source": [
    "optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.0001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 243
    }
   ],
   "source": [
    "optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = torch.randn(105)\n",
    "action = torch.randint(0, 132, (7,))\n",
    "reward = 0\n",
    "next_states = torch.randn(105)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-245-0901947bfa22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcurrent_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-230-9d7fe588540c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0madvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madv_heads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mq_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0madvs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0madvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "current_q = policy(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([128,  58,  30,  27,  31,  52,  78])"
      ]
     },
     "metadata": {},
     "execution_count": 246
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[128],\n",
       "        [ 58],\n",
       "        [ 30],\n",
       "        [ 27],\n",
       "        [ 31],\n",
       "        [ 52],\n",
       "        [ 78]])"
      ]
     },
     "metadata": {},
     "execution_count": 247
    }
   ],
   "source": [
    "action.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Index tensor must have the same number of dimensions as input tensor",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-248-2812875f05b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcurrent_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_q\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Index tensor must have the same number of dimensions as input tensor"
     ]
    }
   ],
   "source": [
    "current_q = current_q.gather(1, action.unsqueeze(1)).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([ 0.0222, -0.0738,  0.1298,  0.1923, -0.0607,  0.0206,  0.1943],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "metadata": {},
     "execution_count": 249
    }
   ],
   "source": [
    "current_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-250-56a5224c517c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0margmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0margmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-230-9d7fe588540c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0madvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madv_heads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mq_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0madvs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0madvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "argmax = torch.argmax(policy(next_states), dim = 1)\n",
    "argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-251-c39e11a401d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmax_next_Q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margmax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmax_next_Q\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-230-9d7fe588540c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0madvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madv_heads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mq_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0madvs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0madvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "max_next_Q = target(next_states).gather(1, argmax.unsqueeze(1)).squeeze(-1)\n",
    "max_next_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.3385], grad_fn=<MeanBackward1>)"
      ]
     },
     "metadata": {},
     "execution_count": 138
    }
   ],
   "source": [
    "max_next_Q = max_next_Q.mean(0, keepdim= True)\n",
    "max_next_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.3047], grad_fn=<AddBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 139
    }
   ],
   "source": [
    "gamma = 0.9\n",
    "expected_Q = reward + max_next_Q * gamma\n",
    "expected_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([ 0.0222, -0.0738,  0.1298,  0.1923, -0.0607,  0.0206,  0.1943],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "metadata": {},
     "execution_count": 140
    }
   ],
   "source": [
    "current_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = F.mse_loss(expected_Q, current_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.0704, grad_fn=<MseLossBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 142
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-1.6957e-02,  1.7050e-02,  1.7803e-02,  ...,  2.1500e-04,\n         -2.5950e-02, -1.5482e-02],\n        [-1.1783e-02,  1.1847e-02,  1.2370e-02,  ...,  1.4939e-04,\n         -1.8031e-02, -1.0758e-02],\n        [ 2.3947e-03, -2.4078e-03, -2.5141e-03,  ..., -3.0362e-05,\n          3.6646e-03,  2.1864e-03],\n        ...,\n        [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n         -0.0000e+00, -0.0000e+00],\n        [-1.4591e-02,  1.4671e-02,  1.5318e-02,  ...,  1.8499e-04,\n         -2.2328e-02, -1.3321e-02],\n        [ 5.5563e-03, -5.5866e-03, -5.8333e-03,  ..., -7.0446e-05,\n          8.5027e-03,  5.0728e-03]])\ntensor([ 1.7696e-02,  1.2296e-02, -2.4991e-03, -1.4139e-02,  0.0000e+00,\n         2.0580e-03,  0.0000e+00, -6.6366e-04,  0.0000e+00,  0.0000e+00,\n        -3.2719e-03,  3.9778e-03,  1.1279e-02, -2.6162e-04,  7.3630e-03,\n         0.0000e+00,  5.7510e-03,  6.5469e-03,  0.0000e+00,  0.0000e+00,\n         0.0000e+00, -9.0092e-04,  3.5018e-03,  0.0000e+00, -9.4276e-03,\n        -1.4437e-03,  0.0000e+00,  9.6752e-03, -1.3344e-02,  0.0000e+00,\n         0.0000e+00, -8.4738e-03, -6.9416e-03,  0.0000e+00, -6.9672e-04,\n         0.0000e+00, -1.1074e-04,  0.0000e+00,  0.0000e+00, -3.6442e-03,\n         0.0000e+00,  0.0000e+00,  7.7079e-03, -1.3303e-02,  2.4836e-03,\n         0.0000e+00, -2.2179e-02,  0.0000e+00, -5.6473e-04,  0.0000e+00,\n         1.5785e-03, -7.7361e-03, -2.5035e-02,  0.0000e+00, -6.2900e-03,\n         2.9688e-03,  0.0000e+00,  0.0000e+00,  1.0730e-02, -1.6022e-02,\n        -1.1202e-02,  0.0000e+00,  0.0000e+00, -3.0210e-03, -9.3027e-05,\n        -7.6521e-03,  2.2050e-03,  2.4201e-03,  2.0957e-03,  3.5284e-03,\n         3.7780e-03,  7.5126e-03,  0.0000e+00, -1.3706e-02,  0.0000e+00,\n         8.1407e-03,  8.5818e-03,  6.4315e-03,  4.7448e-03, -1.0649e-02,\n         0.0000e+00,  0.0000e+00,  3.4856e-03,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00, -5.9040e-03,  0.0000e+00,  0.0000e+00,\n         4.4400e-03,  0.0000e+00,  7.1003e-03,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  7.0857e-05,  1.1037e-02,  0.0000e+00,\n        -6.6208e-03,  0.0000e+00,  9.2564e-03,  0.0000e+00, -7.1084e-03,\n         0.0000e+00,  0.0000e+00,  1.5118e-02,  0.0000e+00,  9.8094e-03,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.0228e-03,\n         1.7006e-02,  0.0000e+00, -4.1587e-03, -1.6661e-02,  0.0000e+00,\n         0.0000e+00, -5.8673e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  1.5227e-02, -5.7984e-03])\ntensor([[ 0.0022,  0.0143,  0.0005,  ...,  0.0000,  0.0076,  0.0141],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        ...,\n        [-0.0021, -0.0135, -0.0004,  ..., -0.0000, -0.0071, -0.0133],\n        [ 0.0049,  0.0312,  0.0010,  ...,  0.0000,  0.0165,  0.0308],\n        [-0.0025, -0.0156, -0.0005,  ..., -0.0000, -0.0083, -0.0154]])\ntensor([ 0.0122,  0.0000,  0.0000,  0.0000,  0.0000,  0.0133,  0.0000,  0.0000,\n        -0.0093,  0.0167, -0.0197,  0.0004,  0.0078, -0.0159,  0.0000,  0.0000,\n         0.0000, -0.0214,  0.0000,  0.0000,  0.0000,  0.0000, -0.0243,  0.0386,\n         0.0000, -0.0247,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0121,\n        -0.0171,  0.0000,  0.0000,  0.0000,  0.0350,  0.0000,  0.0214, -0.0269,\n        -0.0166,  0.0325,  0.0000,  0.0000,  0.0000,  0.0107,  0.0000,  0.0042,\n        -0.0075,  0.0263, -0.0041, -0.0050,  0.0000, -0.0221,  0.0000,  0.0048,\n         0.0000,  0.0000,  0.0000, -0.0125,  0.0000,  0.0000,  0.0012, -0.0104,\n         0.0000, -0.0256,  0.0271,  0.0346,  0.0000,  0.0000,  0.0000,  0.0074,\n        -0.0266,  0.0000,  0.0000,  0.0000,  0.0066, -0.0024,  0.0251,  0.0000,\n         0.0000, -0.0107,  0.0000,  0.0000,  0.0000, -0.0332,  0.0000,  0.0000,\n         0.0000,  0.0000, -0.0197,  0.0000,  0.0000,  0.0000,  0.0000,  0.0542,\n         0.0000, -0.0044,  0.0258, -0.0294,  0.0000,  0.0000,  0.0178, -0.0121,\n         0.0253,  0.0000,  0.0000,  0.0013,  0.0007,  0.0000,  0.0272,  0.0000,\n         0.0000,  0.0000,  0.0000,  0.0222,  0.0365, -0.0209, -0.0235,  0.0000,\n         0.0183,  0.0000,  0.0069,  0.0240, -0.0374, -0.0115,  0.0266, -0.0133])\ntensor([[-0.1769,  0.0000,  0.0000,  0.0000,  0.0000, -0.0263,  0.0000,  0.0000,\n         -0.0587, -0.2374, -0.0402, -0.0394, -0.0467, -0.1752,  0.0000,  0.0000,\n          0.0000, -0.3041,  0.0000,  0.0000,  0.0000,  0.0000, -0.0658, -0.0233,\n          0.0000, -0.1157,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.1944,\n         -0.0376,  0.0000,  0.0000,  0.0000, -0.0744,  0.0000, -0.0578, -0.0816,\n         -0.1031, -0.1462,  0.0000,  0.0000,  0.0000, -0.0520,  0.0000, -0.0731,\n         -0.1937, -0.0309, -0.1636, -0.0791,  0.0000, -0.1606,  0.0000, -0.0761,\n          0.0000,  0.0000,  0.0000, -0.2045,  0.0000,  0.0000, -0.2215, -0.0445,\n          0.0000, -0.1942, -0.1890, -0.0959,  0.0000,  0.0000,  0.0000, -0.2307,\n         -0.1926,  0.0000,  0.0000,  0.0000, -0.2715, -0.1961, -0.2639,  0.0000,\n          0.0000, -0.1762,  0.0000,  0.0000,  0.0000, -0.0726,  0.0000,  0.0000,\n          0.0000,  0.0000, -0.0035,  0.0000,  0.0000,  0.0000,  0.0000, -0.0592,\n          0.0000, -0.0175, -0.1832, -0.0224,  0.0000,  0.0000, -0.2346, -0.1193,\n         -0.0241,  0.0000,  0.0000, -0.1910, -0.0596,  0.0000, -0.0053,  0.0000,\n          0.0000,  0.0000,  0.0000, -0.0337, -0.0377, -0.0509, -0.0121,  0.0000,\n         -0.0036,  0.0000, -0.0411, -0.0818, -0.0443, -0.0893, -0.1344, -0.1264]])\ntensor([-0.4879])\ntensor([[0.0002, 0.0000, 0.0000,  ..., 0.0001, 0.0002, 0.0002],\n        [0.0002, 0.0000, 0.0000,  ..., 0.0001, 0.0002, 0.0002],\n        [0.0002, 0.0000, 0.0000,  ..., 0.0001, 0.0002, 0.0002],\n        ...,\n        [0.0002, 0.0000, 0.0000,  ..., 0.0001, 0.0002, 0.0002],\n        [0.0002, 0.0000, 0.0000,  ..., 0.0001, 0.0002, 0.0002],\n        [0.0002, 0.0000, 0.0000,  ..., 0.0001, 0.0002, 0.0002]])\ntensor([ 0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,\n         0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,\n         0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,\n         0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,\n         0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,\n         0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,\n         0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,\n         0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,\n         0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,\n         0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006, -0.0801,\n         0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,\n         0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,\n         0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,\n         0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,\n         0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,\n         0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,\n         0.0006,  0.0006,  0.0006,  0.0006])\ntensor([[0.0003, 0.0000, 0.0000,  ..., 0.0001, 0.0002, 0.0002],\n        [0.0003, 0.0000, 0.0000,  ..., 0.0001, 0.0002, 0.0002],\n        [0.0003, 0.0000, 0.0000,  ..., 0.0001, 0.0002, 0.0002],\n        ...,\n        [0.0003, 0.0000, 0.0000,  ..., 0.0001, 0.0002, 0.0002],\n        [0.0003, 0.0000, 0.0000,  ..., 0.0001, 0.0002, 0.0002],\n        [0.0003, 0.0000, 0.0000,  ..., 0.0001, 0.0002, 0.0002]])\ntensor([ 0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,\n         0.0008, -0.1073,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,\n         0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,\n         0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,\n         0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,\n         0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,\n         0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,\n         0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,\n         0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,\n         0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,\n         0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,\n         0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,\n         0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,\n         0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,\n         0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,\n         0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,\n         0.0008,  0.0008,  0.0008,  0.0008])\ntensor([[1.3727e-04, 0.0000e+00, 0.0000e+00,  ..., 6.9269e-05, 1.0425e-04,\n         9.8054e-05],\n        [1.3727e-04, 0.0000e+00, 0.0000e+00,  ..., 6.9269e-05, 1.0425e-04,\n         9.8054e-05],\n        [1.3727e-04, 0.0000e+00, 0.0000e+00,  ..., 6.9269e-05, 1.0425e-04,\n         9.8054e-05],\n        ...,\n        [1.3727e-04, 0.0000e+00, 0.0000e+00,  ..., 6.9269e-05, 1.0425e-04,\n         9.8054e-05],\n        [1.3727e-04, 0.0000e+00, 0.0000e+00,  ..., 6.9269e-05, 1.0425e-04,\n         9.8054e-05],\n        [1.3727e-04, 0.0000e+00, 0.0000e+00,  ..., 6.9269e-05, 1.0425e-04,\n         9.8054e-05]])\ntensor([ 0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,\n         0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,\n         0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,\n         0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,\n         0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,\n         0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,\n         0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,\n         0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,\n         0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,\n         0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,\n         0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,\n         0.0004, -0.0496,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,\n         0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,\n         0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,\n         0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,\n         0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,\n         0.0004,  0.0004,  0.0004,  0.0004])\ntensor([[8.8155e-05, 0.0000e+00, 0.0000e+00,  ..., 4.4484e-05, 6.6946e-05,\n         6.2969e-05],\n        [8.8155e-05, 0.0000e+00, 0.0000e+00,  ..., 4.4484e-05, 6.6946e-05,\n         6.2969e-05],\n        [8.8155e-05, 0.0000e+00, 0.0000e+00,  ..., 4.4484e-05, 6.6946e-05,\n         6.2969e-05],\n        ...,\n        [8.8155e-05, 0.0000e+00, 0.0000e+00,  ..., 4.4484e-05, 6.6946e-05,\n         6.2969e-05],\n        [8.8155e-05, 0.0000e+00, 0.0000e+00,  ..., 4.4484e-05, 6.6946e-05,\n         6.2969e-05],\n        [8.8155e-05, 0.0000e+00, 0.0000e+00,  ..., 4.4484e-05, 6.6946e-05,\n         6.2969e-05]])\ntensor([ 0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n         0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n         0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n         0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n         0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n         0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n         0.0002,  0.0002, -0.0318,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n         0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n         0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n         0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n         0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n         0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n         0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n         0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n         0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n         0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n         0.0002,  0.0002,  0.0002,  0.0002])\ntensor([[0.0003, 0.0000, 0.0000,  ..., 0.0001, 0.0002, 0.0002],\n        [0.0003, 0.0000, 0.0000,  ..., 0.0001, 0.0002, 0.0002],\n        [0.0003, 0.0000, 0.0000,  ..., 0.0001, 0.0002, 0.0002],\n        ...,\n        [0.0003, 0.0000, 0.0000,  ..., 0.0001, 0.0002, 0.0002],\n        [0.0003, 0.0000, 0.0000,  ..., 0.0001, 0.0002, 0.0002],\n        [0.0003, 0.0000, 0.0000,  ..., 0.0001, 0.0002, 0.0002]])\ntensor([ 0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,\n         0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,\n         0.0008,  0.0008,  0.0008,  0.0008, -0.1036,  0.0008,  0.0008,  0.0008,\n         0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,\n         0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,\n         0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,\n         0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,\n         0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,\n         0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,\n         0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,\n         0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,\n         0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,\n         0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,\n         0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,\n         0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,\n         0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,  0.0008,\n         0.0008,  0.0008,  0.0008,  0.0008])\ntensor([[0.0002, 0.0000, 0.0000,  ..., 0.0001, 0.0002, 0.0002],\n        [0.0002, 0.0000, 0.0000,  ..., 0.0001, 0.0002, 0.0002],\n        [0.0002, 0.0000, 0.0000,  ..., 0.0001, 0.0002, 0.0002],\n        ...,\n        [0.0002, 0.0000, 0.0000,  ..., 0.0001, 0.0002, 0.0002],\n        [0.0002, 0.0000, 0.0000,  ..., 0.0001, 0.0002, 0.0002],\n        [0.0002, 0.0000, 0.0000,  ..., 0.0001, 0.0002, 0.0002]])\ntensor([ 0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,\n         0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,\n         0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,\n         0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,\n         0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,\n         0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,\n         0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,\n         0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,\n         0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,\n        -0.0805,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,\n         0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,\n         0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,\n         0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,\n         0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,\n         0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,\n         0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,  0.0006,\n         0.0006,  0.0006,  0.0006,  0.0006])\ntensor([[8.6587e-05, 0.0000e+00, 0.0000e+00,  ..., 4.3692e-05, 6.5755e-05,\n         6.1849e-05],\n        [8.6587e-05, 0.0000e+00, 0.0000e+00,  ..., 4.3692e-05, 6.5755e-05,\n         6.1849e-05],\n        [8.6587e-05, 0.0000e+00, 0.0000e+00,  ..., 4.3692e-05, 6.5755e-05,\n         6.1849e-05],\n        ...,\n        [8.6587e-05, 0.0000e+00, 0.0000e+00,  ..., 4.3692e-05, 6.5755e-05,\n         6.1849e-05],\n        [8.6587e-05, 0.0000e+00, 0.0000e+00,  ..., 4.3692e-05, 6.5755e-05,\n         6.1849e-05],\n        [8.6587e-05, 0.0000e+00, 0.0000e+00,  ..., 4.3692e-05, 6.5755e-05,\n         6.1849e-05]])\ntensor([ 0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n         0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n         0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n         0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n         0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n         0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n         0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n         0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n         0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n         0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n         0.0002,  0.0002,  0.0002,  0.0002,  0.0002, -0.0313,  0.0002,  0.0002,\n         0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n         0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n         0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n         0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n         0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n         0.0002,  0.0002,  0.0002,  0.0002])\n"
     ]
    }
   ],
   "source": [
    "for p in policy.parameters():\n",
    "    print(p.grad.data.clamp_(-1.,1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(0.07035503, dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 146
    }
   ],
   "source": [
    "loss.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-1.        , -0.98473282, -0.96946565, -0.95419847, -0.9389313 ,\n",
       "       -0.92366412, -0.90839695, -0.89312977, -0.8778626 , -0.86259542,\n",
       "       -0.84732824, -0.83206107, -0.81679389, -0.80152672, -0.78625954,\n",
       "       -0.77099237, -0.75572519, -0.74045802, -0.72519084, -0.70992366,\n",
       "       -0.69465649, -0.67938931, -0.66412214, -0.64885496, -0.63358779,\n",
       "       -0.61832061, -0.60305344, -0.58778626, -0.57251908, -0.55725191,\n",
       "       -0.54198473, -0.52671756, -0.51145038, -0.49618321, -0.48091603,\n",
       "       -0.46564885, -0.45038168, -0.4351145 , -0.41984733, -0.40458015,\n",
       "       -0.38931298, -0.3740458 , -0.35877863, -0.34351145, -0.32824427,\n",
       "       -0.3129771 , -0.29770992, -0.28244275, -0.26717557, -0.2519084 ,\n",
       "       -0.23664122, -0.22137405, -0.20610687, -0.19083969, -0.17557252,\n",
       "       -0.16030534, -0.14503817, -0.12977099, -0.11450382, -0.09923664,\n",
       "       -0.08396947, -0.06870229, -0.05343511, -0.03816794, -0.02290076,\n",
       "       -0.00763359,  0.00763359,  0.02290076,  0.03816794,  0.05343511,\n",
       "        0.06870229,  0.08396947,  0.09923664,  0.11450382,  0.12977099,\n",
       "        0.14503817,  0.16030534,  0.17557252,  0.19083969,  0.20610687,\n",
       "        0.22137405,  0.23664122,  0.2519084 ,  0.26717557,  0.28244275,\n",
       "        0.29770992,  0.3129771 ,  0.32824427,  0.34351145,  0.35877863,\n",
       "        0.3740458 ,  0.38931298,  0.40458015,  0.41984733,  0.4351145 ,\n",
       "        0.45038168,  0.46564885,  0.48091603,  0.49618321,  0.51145038,\n",
       "        0.52671756,  0.54198473,  0.55725191,  0.57251908,  0.58778626,\n",
       "        0.60305344,  0.61832061,  0.63358779,  0.64885496,  0.66412214,\n",
       "        0.67938931,  0.69465649,  0.70992366,  0.72519084,  0.74045802,\n",
       "        0.75572519,  0.77099237,  0.78625954,  0.80152672,  0.81679389,\n",
       "        0.83206107,  0.84732824,  0.86259542,  0.8778626 ,  0.89312977,\n",
       "        0.90839695,  0.92366412,  0.9389313 ,  0.95419847,  0.96946565,\n",
       "        0.98473282,  1.        ])"
      ]
     },
     "metadata": {},
     "execution_count": 147
    }
   ],
   "source": [
    "np.linspace(-1,1,132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import random_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.0830, 0.4124, 0.4551, 0.7671, 0.0220, 0.4815, 0.2063, 0.5051, 0.8469,\n",
       "        0.2096, 0.1656, 0.3348, 0.3794, 0.9347, 0.0801, 0.8967, 0.5704, 0.4535,\n",
       "        0.9292, 0.8787, 0.2121, 0.5989, 0.2332, 0.0244, 0.9013, 0.7997, 0.6940,\n",
       "        0.7609, 0.8513, 0.6706, 0.0253, 0.6127, 0.6415, 0.1296, 0.7249, 0.2447,\n",
       "        0.2483, 0.6806, 0.7105, 0.8748, 0.1033, 0.2845, 0.3112, 0.0772, 0.6148,\n",
       "        0.7666, 0.8586, 0.1589, 0.7170, 0.4426, 0.6796, 0.2370, 0.0555, 0.4510,\n",
       "        0.4587, 0.8502, 0.9431, 0.6341, 0.3209, 0.5310, 0.6800, 0.8095, 0.9145,\n",
       "        0.7502, 0.0820, 0.5155, 0.4397, 0.9034, 0.8119, 0.5759, 0.9849, 0.4811,\n",
       "        0.5467, 0.0479, 0.0401, 0.5424, 0.8481, 0.5568, 0.9336, 0.9873, 0.4090,\n",
       "        0.0657, 0.2453, 0.9925, 0.8555, 0.5105, 0.5742, 0.5474, 0.4210, 0.2494,\n",
       "        0.4915, 0.3038, 0.9954, 0.0177, 0.0111, 0.5225, 0.8991, 0.8292, 0.3535,\n",
       "        0.5642, 0.4810, 0.2727, 0.1918, 0.4364, 0.1598])"
      ]
     },
     "metadata": {},
     "execution_count": 161
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-1.9976],\n",
       "        [-1.1203],\n",
       "        [ 0.2147],\n",
       "        [-0.0185],\n",
       "        [ 0.2793],\n",
       "        [ 1.1793],\n",
       "        [ 0.6820],\n",
       "        [ 0.6447],\n",
       "        [-0.3260],\n",
       "        [ 1.2579],\n",
       "        [ 1.2375],\n",
       "        [-0.0345],\n",
       "        [ 0.3433],\n",
       "        [-0.8174],\n",
       "        [-0.9680],\n",
       "        [-0.1885],\n",
       "        [ 2.0348],\n",
       "        [ 0.0435],\n",
       "        [-0.4866],\n",
       "        [-0.9170],\n",
       "        [-0.7190],\n",
       "        [-0.8577],\n",
       "        [ 1.2513],\n",
       "        [ 0.9863],\n",
       "        [-0.3322],\n",
       "        [ 1.3322],\n",
       "        [ 0.6440],\n",
       "        [-0.3353],\n",
       "        [ 0.7583],\n",
       "        [ 0.9740],\n",
       "        [ 0.8674],\n",
       "        [-0.6346],\n",
       "        [ 1.6965],\n",
       "        [ 0.7996],\n",
       "        [ 1.5226],\n",
       "        [ 0.3301],\n",
       "        [ 0.8336],\n",
       "        [ 1.0484],\n",
       "        [ 0.8192],\n",
       "        [ 0.7407],\n",
       "        [-0.3717],\n",
       "        [-0.7547],\n",
       "        [-1.0736],\n",
       "        [ 0.6281],\n",
       "        [ 0.9393],\n",
       "        [ 0.2530],\n",
       "        [ 0.5603],\n",
       "        [-0.2607],\n",
       "        [ 1.5920],\n",
       "        [-0.9475],\n",
       "        [ 1.5873],\n",
       "        [ 1.2639],\n",
       "        [ 0.5020],\n",
       "        [ 0.1529],\n",
       "        [-1.3445],\n",
       "        [ 0.0747],\n",
       "        [ 0.0613],\n",
       "        [-0.4276],\n",
       "        [ 1.1866],\n",
       "        [ 0.5992],\n",
       "        [-0.0746],\n",
       "        [ 0.2932],\n",
       "        [-0.0859],\n",
       "        [-0.8529]])"
      ]
     },
     "metadata": {},
     "execution_count": 209
    }
   ],
   "source": [
    "value = torch.randn((64,1))\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[-1.2068, -1.8954,  0.7135,  ...,  0.6088,  1.2021,  0.2778],\n",
       "         [-0.5118, -2.1357, -0.6352,  ..., -1.2942, -0.1597,  0.7676],\n",
       "         [-1.6877,  1.0168, -0.1525,  ..., -0.0268, -0.2852, -1.5458],\n",
       "         ...,\n",
       "         [ 0.7653,  0.1356, -0.0030,  ..., -0.1031,  0.3148, -1.7624],\n",
       "         [-0.9435,  1.1407,  0.1247,  ...,  0.9815, -1.3269,  0.4010],\n",
       "         [-0.5127, -1.4620, -0.8592,  ...,  0.1655,  1.0872,  1.7804]],\n",
       "\n",
       "        [[ 1.0501, -0.4752, -0.6338,  ..., -1.9583, -1.1993, -1.3766],\n",
       "         [ 0.3150,  0.6708, -1.4899,  ...,  1.0364,  0.6407, -1.2041],\n",
       "         [ 0.1459, -0.0709, -1.1831,  ..., -0.2040,  2.2404, -0.9640],\n",
       "         ...,\n",
       "         [ 1.2132,  0.0829,  1.0483,  ..., -1.0633, -0.7850,  0.4201],\n",
       "         [ 0.4292,  0.3170, -0.1012,  ..., -0.7528, -0.1740,  0.3959],\n",
       "         [ 1.0836,  0.7134,  1.2918,  ...,  0.7371,  0.2850,  0.6737]],\n",
       "\n",
       "        [[ 0.0396, -1.0044, -0.2219,  ..., -0.4046,  1.8610,  1.8611],\n",
       "         [-0.4089,  0.2014,  0.5535,  ..., -0.1866,  1.5262,  0.0275],\n",
       "         [-0.2369, -0.7294,  0.6093,  ...,  1.5981,  0.8814, -2.4715],\n",
       "         ...,\n",
       "         [ 1.4663, -0.6437,  0.4276,  ..., -0.2129, -0.0220,  0.3292],\n",
       "         [-0.3693,  0.7675,  0.7997,  ...,  2.4374, -2.8173, -0.6197],\n",
       "         [-1.0291, -0.0224, -0.2751,  ..., -1.1384,  2.3924, -0.1037]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.2224, -0.4054, -0.7370,  ..., -2.3542, -1.0654,  0.3330],\n",
       "         [ 0.0606,  0.2942,  0.6411,  ...,  1.0765,  0.3995, -1.2979],\n",
       "         [-0.4804, -0.3071, -0.3212,  ..., -0.9694,  0.4085, -1.7461],\n",
       "         ...,\n",
       "         [-1.7827,  0.6895, -0.7586,  ...,  0.6833,  1.1443, -0.6866],\n",
       "         [ 0.3321,  0.9199,  0.3401,  ..., -0.3850,  0.1878,  0.3288],\n",
       "         [ 0.0261,  0.4345,  0.0908,  ...,  1.1286, -2.0492, -1.0474]],\n",
       "\n",
       "        [[-0.9243,  0.2195, -1.6714,  ...,  0.3026, -1.6881,  0.7620],\n",
       "         [-0.8149, -0.5654,  0.2925,  ..., -0.6069, -0.6280, -1.0303],\n",
       "         [-0.1914,  1.0217, -2.2857,  ..., -0.2060,  1.7423,  0.2597],\n",
       "         ...,\n",
       "         [-0.8473,  0.0228,  0.2831,  ..., -2.3617, -1.9385,  0.7717],\n",
       "         [ 0.6248, -0.3596,  0.5136,  ...,  0.5108, -0.2840,  0.3848],\n",
       "         [-0.0640,  0.5515, -0.2967,  ...,  0.4828,  0.8661,  0.4246]],\n",
       "\n",
       "        [[-1.7995,  0.4414,  1.5474,  ..., -1.3270,  1.4915, -0.7480],\n",
       "         [-1.4753, -0.4187,  0.3161,  ..., -1.0683, -2.0985, -0.7791],\n",
       "         [-1.0425, -0.1348,  0.3460,  ...,  1.3564, -1.1447, -0.3895],\n",
       "         ...,\n",
       "         [-1.1125, -0.6657,  0.5535,  ...,  0.1471,  1.5096, -0.2471],\n",
       "         [ 0.8725,  1.2439,  1.1270,  ..., -0.5793, -1.1357, -0.4224],\n",
       "         [ 1.5872,  1.9846, -0.5061,  ..., -0.6576,  1.9842,  0.5325]]])"
      ]
     },
     "metadata": {},
     "execution_count": 210
    }
   ],
   "source": [
    "advs = torch.randn((64,7,132))\n",
    "advs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 211
    }
   ],
   "source": [
    "value.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = value.unsqueeze(1) + advs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([64, 7, 132])"
      ]
     },
     "metadata": {},
     "execution_count": 214
    }
   ],
   "source": [
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([64, 7, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 215
    }
   ],
   "source": [
    "advs.mean(2, keepdim=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[-3.2301, -3.9187, -1.3097,  ..., -1.4144, -0.8212, -1.7455],\n",
       "         [-2.4812, -4.1052, -2.6046,  ..., -3.2636, -2.1292, -1.2018],\n",
       "         [-3.7376, -1.0331, -2.2024,  ..., -2.0767, -2.3351, -3.5957],\n",
       "         ...,\n",
       "         [-1.2969, -1.9265, -2.0652,  ..., -2.1653, -1.7474, -3.8245],\n",
       "         [-3.0152, -0.9309, -1.9469,  ..., -1.0901, -3.3985, -1.6706],\n",
       "         [-2.7327, -3.6820, -3.0793,  ..., -2.0545, -1.1328, -0.4396]],\n",
       "\n",
       "        [[ 0.0384, -1.4869, -1.6455,  ..., -2.9700, -2.2111, -2.3883],\n",
       "         [-0.8923, -0.5365, -2.6972,  ..., -0.1709, -0.5665, -2.4114],\n",
       "         [-0.9249, -1.1417, -2.2540,  ..., -1.2748,  1.1696, -2.0348],\n",
       "         ...,\n",
       "         [ 0.2436, -0.8867,  0.0787,  ..., -2.0329, -1.7547, -0.5495],\n",
       "         [-0.7592, -0.8714, -1.2896,  ..., -1.9412, -1.3624, -0.7925],\n",
       "         [-0.1113, -0.4815,  0.0970,  ..., -0.4577, -0.9099, -0.5212]],\n",
       "\n",
       "        [[ 0.2998, -0.7442,  0.0384,  ..., -0.1444,  2.1212,  2.1213],\n",
       "         [-0.1629,  0.4475,  0.7996,  ...,  0.0594,  1.7723,  0.2736],\n",
       "         [ 0.0916, -0.4009,  0.9378,  ...,  1.9266,  1.2099, -2.1430],\n",
       "         ...,\n",
       "         [ 1.7796, -0.3303,  0.7410,  ...,  0.1004,  0.2914,  0.6426],\n",
       "         [-0.1689,  0.9679,  1.0001,  ...,  2.6378, -2.6169, -0.4193],\n",
       "         [-0.6907,  0.3159,  0.0632,  ..., -0.8001,  2.7307,  0.2346]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.2315,  0.0485, -0.2831,  ..., -1.9003, -0.6115,  0.7869],\n",
       "         [ 0.2119,  0.4455,  0.7924,  ...,  1.2278,  0.5508, -1.1466],\n",
       "         [-0.0843,  0.0890,  0.0749,  ..., -0.5733,  0.8046, -1.3500],\n",
       "         ...,\n",
       "         [-1.2656,  1.2065, -0.2415,  ...,  1.2004,  1.6614, -0.1695],\n",
       "         [ 0.6519,  1.2397,  0.6599,  ..., -0.0652,  0.5076,  0.6486],\n",
       "         [ 0.4559,  0.8643,  0.5207,  ...,  1.5585, -1.6194, -0.6175]],\n",
       "\n",
       "        [[-0.8097,  0.3341, -1.5568,  ...,  0.4172, -1.5735,  0.8766],\n",
       "         [-0.9581, -0.7087,  0.1492,  ..., -0.7502, -0.7713, -1.1735],\n",
       "         [-0.2337,  0.9794, -2.3279,  ..., -0.2482,  1.7000,  0.2175],\n",
       "         ...,\n",
       "         [-0.7365,  0.1336,  0.3939,  ..., -2.2509, -1.8277,  0.8825],\n",
       "         [ 0.5260, -0.4584,  0.4148,  ...,  0.4120, -0.3828,  0.2861],\n",
       "         [-0.1321,  0.4834, -0.3648,  ...,  0.4147,  0.7980,  0.3565]],\n",
       "\n",
       "        [[-2.7125, -0.4716,  0.6344,  ..., -2.2400,  0.5785, -1.6611],\n",
       "         [-2.4281, -1.3715, -0.6367,  ..., -2.0211, -3.0513, -1.7319],\n",
       "         [-1.7632, -0.8555, -0.3747,  ...,  0.6357, -1.8655, -1.1102],\n",
       "         ...,\n",
       "         [-1.9474, -1.5007, -0.2815,  ..., -0.6879,  0.6746, -1.0820],\n",
       "         [-0.0779,  0.2935,  0.1765,  ..., -1.5297, -2.0861, -1.3728],\n",
       "         [ 0.6655,  1.0630, -1.4277,  ..., -1.5793,  1.0625, -0.3892]]])"
      ]
     },
     "metadata": {},
     "execution_count": 216
    }
   ],
   "source": [
    "q = value.unsqueeze(1) + advs - advs.mean(2, keepdim=True)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = torch.randn(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.randn((7,132))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = o+u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 1.4819e+00, -1.3352e-01, -2.1356e-01, -1.0911e-01,  3.5015e-01,\n",
       "         -8.1715e-01, -3.6989e-01, -5.2305e-01, -7.0415e-01, -1.9973e-01,\n",
       "         -1.5695e-01, -1.0467e+00, -4.7138e-02, -1.7400e+00,  1.3744e-01,\n",
       "         -1.3786e+00, -1.5015e+00,  1.5167e+00, -1.0429e+00, -1.1815e+00,\n",
       "          1.0425e+00, -1.4569e+00,  1.1000e+00, -2.3858e-01, -2.0129e+00,\n",
       "         -3.2355e-01,  6.7169e-01, -6.2313e-01,  2.6437e-01, -8.8893e-01,\n",
       "         -4.3484e-01,  5.4433e-01, -1.7005e-01, -4.9023e-02, -7.5233e-01,\n",
       "          1.9230e+00, -9.0301e-01, -8.6664e-01, -2.3282e+00,  1.4146e+00,\n",
       "         -1.9020e+00, -1.2407e+00, -1.1215e+00, -1.2402e+00,  1.1807e+00,\n",
       "         -2.0173e+00, -1.6553e+00, -9.1408e-01, -3.9930e-01, -5.3499e-01,\n",
       "          9.0881e-01, -2.2047e+00,  1.1509e+00, -1.5209e+00, -2.5986e-01,\n",
       "          1.8174e+00, -8.7037e-01, -1.9622e+00,  2.7286e-01, -1.5236e-01,\n",
       "          7.3695e-02, -3.1806e-01, -5.8360e-04,  2.0717e-01,  7.3171e-01,\n",
       "          3.6343e-01, -5.5504e-01, -4.3852e-01, -1.6513e+00, -1.2881e+00,\n",
       "         -1.9567e+00,  1.6111e+00, -1.9556e-01, -1.7966e+00, -2.4396e-01,\n",
       "         -1.4369e+00,  4.4188e-01,  6.5126e-01, -8.1990e-02, -1.2813e-01,\n",
       "         -1.4254e+00, -2.5102e+00, -6.0443e-02,  8.5343e-01, -1.8994e-01,\n",
       "         -2.4697e+00, -2.4684e-01, -8.0484e-03, -3.1482e-01,  1.8789e-01,\n",
       "         -5.3900e-01,  4.7645e-01, -1.4488e+00,  7.5338e-01,  1.0809e+00,\n",
       "          1.7151e-01, -1.3421e+00, -1.5525e-03, -6.7898e-01,  7.9308e-03,\n",
       "          1.7351e+00,  8.7290e-01, -8.2767e-01,  1.3969e+00, -2.2020e+00,\n",
       "         -5.1459e-01,  1.9154e-01, -5.2327e-01, -8.2706e-01, -1.0547e-01,\n",
       "         -4.1703e-01,  3.0333e-01, -2.3604e+00,  1.0469e+00, -1.1276e+00,\n",
       "         -1.7600e-01, -1.8190e+00, -1.5231e+00, -7.6292e-01,  1.2195e+00,\n",
       "          2.6340e-01, -1.5594e-01,  5.2405e-02, -4.0390e-01, -4.1095e-01,\n",
       "          1.9875e-01, -3.2613e-01, -8.0855e-01, -1.1043e+00, -1.8616e+00,\n",
       "         -1.3164e-01, -8.4109e-01],\n",
       "        [-8.3446e-01, -1.2829e-01,  6.1269e-01, -6.9667e-01, -1.0235e+00,\n",
       "         -2.7350e+00, -1.4353e-01, -7.2165e-01, -4.0903e-01,  2.1104e-01,\n",
       "          8.7376e-01, -5.1871e-01, -1.2595e+00, -7.9801e-01, -1.7852e-01,\n",
       "          4.5274e-02, -3.7035e-01,  4.0322e-01,  3.4352e-01,  2.0834e-01,\n",
       "         -1.6109e+00,  1.3173e+00, -9.2426e-01,  3.4622e-01, -7.8824e-01,\n",
       "         -1.4519e-01,  3.9586e-01, -2.6962e-01,  5.1104e-02, -2.1828e+00,\n",
       "         -6.5216e-01,  3.3949e-01, -1.7518e+00,  9.3102e-01, -3.8070e-01,\n",
       "         -2.1787e+00, -1.7152e-01, -5.5571e-01, -1.5769e+00, -7.9808e-01,\n",
       "          6.2683e-02,  8.9346e-01, -5.9899e-01,  1.1996e+00,  1.6742e+00,\n",
       "          7.9414e-02, -3.1105e-01, -2.0851e-01,  6.7670e-01, -1.1006e+00,\n",
       "         -2.3728e-01,  4.1589e-01, -4.4142e-01, -5.3236e-01, -3.5855e-01,\n",
       "         -6.2421e-01,  7.7537e-01, -8.3111e-02, -2.7339e-01,  8.9076e-02,\n",
       "         -2.3476e-01, -6.3534e-02,  3.3055e-01, -3.1659e-01,  1.4619e+00,\n",
       "          4.9227e-01, -3.7484e-01, -6.4118e-01,  3.4798e-01, -2.0565e+00,\n",
       "         -1.8058e-01, -9.6988e-01,  1.0611e+00, -1.7244e+00, -2.7166e-01,\n",
       "         -9.9910e-01, -1.1765e+00,  8.1751e-01,  5.6132e-01, -1.0604e+00,\n",
       "         -3.7598e-01, -1.6153e+00, -2.8663e-01,  3.9119e-01,  8.3193e-03,\n",
       "         -2.7159e+00, -3.0753e-03,  1.4731e+00,  1.0645e+00, -2.1648e-01,\n",
       "         -1.1803e+00, -1.7059e+00, -4.7519e-01, -1.7627e+00, -4.9033e-01,\n",
       "          6.6781e-02,  1.7362e-01, -2.7165e+00, -1.0139e-01, -5.3106e-01,\n",
       "         -7.8753e-02, -3.4553e-01, -9.9773e-01,  8.8865e-01, -1.8044e+00,\n",
       "         -6.8954e-01, -1.8602e+00, -9.2070e-01, -1.8570e+00, -7.6113e-01,\n",
       "         -1.0779e+00,  1.0376e+00, -5.3821e-01, -1.2133e+00, -9.0922e-01,\n",
       "          1.6075e+00,  1.3396e+00,  8.0188e-01, -1.2491e-01,  1.2881e+00,\n",
       "         -1.2280e+00, -1.2314e+00,  2.3911e+00, -1.2749e+00,  7.8191e-01,\n",
       "          2.3788e-01, -1.6140e+00, -2.5821e-01,  1.7477e+00, -5.3760e-02,\n",
       "         -2.0221e-01,  7.9517e-01],\n",
       "        [-1.8499e+00, -4.2144e-01, -1.4114e+00, -1.7335e+00, -8.4818e-01,\n",
       "         -1.4724e+00,  1.5336e+00, -7.2826e-01,  1.5086e+00, -2.2113e+00,\n",
       "          4.2959e-02, -8.9600e-01, -8.6199e-01, -1.3150e+00, -6.8105e-01,\n",
       "          2.1501e+00, -4.7897e-01, -5.3134e-01, -1.4778e-01,  2.3302e+00,\n",
       "         -2.8822e+00, -6.1421e-01,  7.6720e-01,  2.3211e-01, -9.4309e-01,\n",
       "          1.2202e+00, -5.6682e-01, -2.6602e-01, -1.8678e+00, -1.4303e+00,\n",
       "         -1.9512e+00,  1.2505e-01,  8.6242e-02,  9.9548e-02,  3.4351e-01,\n",
       "          5.3615e-01,  1.4156e+00,  6.0996e-01,  8.9783e-01, -1.0221e+00,\n",
       "          9.8276e-01, -6.7087e-02,  9.8723e-01, -1.4177e-03,  5.1132e-01,\n",
       "          7.9771e-01,  1.4788e+00,  6.7964e-01,  5.7393e-01, -1.0421e+00,\n",
       "          1.1821e+00,  1.3103e+00, -7.0672e-01, -6.2934e-01,  1.8044e+00,\n",
       "         -8.6181e-01, -7.2269e-01, -7.8625e-01, -8.2421e-02, -1.1238e+00,\n",
       "         -1.6168e+00,  9.0069e-01,  6.6975e-01,  8.8042e-02,  8.3902e-02,\n",
       "          6.2697e-01,  8.5986e-01, -5.3419e-01, -1.5130e+00, -2.0470e+00,\n",
       "          1.2074e+00, -3.9410e-01, -5.6585e-01,  1.0377e+00,  8.3839e-02,\n",
       "         -1.3066e+00,  7.7486e-01, -7.2317e-01,  1.3510e+00, -4.6908e-01,\n",
       "          8.8211e-01,  5.9683e-02, -1.0928e-01,  8.9354e-01,  2.7916e-01,\n",
       "         -1.6881e-01,  6.2935e-01, -8.6212e-01,  1.8632e-01, -1.4253e+00,\n",
       "          9.4633e-02,  8.2523e-02, -1.1613e+00, -1.5798e-01, -9.2453e-01,\n",
       "          2.0830e+00,  1.5331e+00,  1.0314e+00, -1.8971e-01, -2.0674e-02,\n",
       "          6.8902e-01, -9.8707e-01, -1.0745e+00, -8.9424e-01,  2.0525e+00,\n",
       "          1.7827e+00, -3.4519e-02, -1.2487e+00,  2.5163e-02, -6.4066e-01,\n",
       "         -1.9827e+00, -3.3896e+00,  1.8516e-01,  4.2909e-01,  1.2773e-02,\n",
       "         -2.9432e-01, -1.9742e+00, -6.6380e-01, -1.4235e+00, -7.4126e-01,\n",
       "         -1.1070e+00,  1.5272e+00,  1.1389e-02, -1.1725e+00, -1.5005e+00,\n",
       "          9.4103e-01, -5.6287e-01,  4.9787e-01, -1.8129e-01,  4.3074e-01,\n",
       "         -6.0978e-01, -1.0645e+00],\n",
       "        [ 1.8762e-01,  4.4518e-01, -2.0963e+00, -8.5536e-01, -1.1398e+00,\n",
       "         -1.5669e+00, -2.3803e+00, -1.2152e+00, -1.9230e+00,  1.9021e+00,\n",
       "          5.8861e-01, -5.3095e-01, -9.9195e-01, -9.5475e-01,  1.2055e+00,\n",
       "         -2.7504e-01, -5.5347e-01, -5.5492e-01, -5.7786e-01,  5.7623e-01,\n",
       "         -2.3142e-01,  1.4885e+00, -3.4198e-01, -1.1341e+00, -4.5918e-01,\n",
       "          9.9981e-02, -2.9542e-01, -6.0937e-01,  2.9309e-01,  7.7377e-01,\n",
       "         -1.4664e-01, -1.4806e+00,  2.0370e-01, -6.8852e-01, -1.1291e+00,\n",
       "         -1.1014e-01,  1.0418e+00, -1.5037e+00, -1.7351e+00,  7.8718e-01,\n",
       "         -2.6363e-01, -8.0749e-01, -8.4249e-01,  1.5044e-01, -1.8649e+00,\n",
       "         -4.9073e-01, -1.3965e+00, -2.1380e+00, -1.3907e+00, -8.1778e-01,\n",
       "          1.5826e-01, -9.7666e-01,  1.0178e+00, -6.2013e-01,  4.7076e-01,\n",
       "          3.4011e-01,  1.5512e+00,  8.4482e-01, -2.7797e-01,  1.7324e+00,\n",
       "         -6.6971e-01,  1.5004e+00, -5.0503e-01,  1.6523e+00,  6.8316e-01,\n",
       "          9.8373e-02, -1.9029e-01, -4.6581e-01, -1.3568e+00, -8.1942e-01,\n",
       "          2.7824e-01,  4.7435e-01, -2.0812e-01, -8.0693e-01, -1.7274e-01,\n",
       "          8.2782e-02, -8.9351e-02,  3.6927e-01,  4.5343e-01,  1.1770e+00,\n",
       "         -2.1998e-01, -3.3856e-02,  6.4669e-01, -4.4450e-01,  5.9198e-01,\n",
       "          3.5680e-01, -2.0273e+00, -3.1365e-01, -2.4034e+00, -1.3188e+00,\n",
       "         -1.8843e+00, -1.6510e+00, -1.3349e+00, -9.1063e-01,  5.9639e-01,\n",
       "         -2.2693e+00, -2.1126e-01,  5.9816e-01, -2.2583e+00,  1.2370e-01,\n",
       "          1.4171e+00, -4.8294e-01,  2.8438e-01, -3.7026e-01, -2.6048e-01,\n",
       "         -3.6962e-01,  1.1954e+00, -1.3384e+00,  1.0467e-01, -1.8094e-01,\n",
       "          1.9858e+00, -1.7611e+00, -7.5923e-01, -3.7042e-01,  1.1529e+00,\n",
       "         -5.3844e-01, -1.2475e+00, -1.9491e+00,  3.1558e-01,  4.4719e-01,\n",
       "         -5.3853e-04,  1.0570e+00,  1.7119e-01,  1.2968e+00,  1.1038e+00,\n",
       "          8.8081e-01,  1.5833e+00, -7.4622e-02, -7.1039e-01, -8.2372e-01,\n",
       "         -1.3430e-01,  9.6161e-01],\n",
       "        [ 1.8167e-01,  3.9736e-01, -6.0177e-01, -1.0724e+00, -9.9647e-01,\n",
       "          2.9443e-02,  1.9233e+00, -2.5846e+00, -8.1545e-01,  9.0826e-01,\n",
       "         -2.2999e+00,  1.4680e+00, -6.1093e-01,  1.8847e+00,  8.2275e-01,\n",
       "         -5.2047e-02,  1.3504e+00, -3.0058e-01, -8.1249e-02,  1.4338e+00,\n",
       "         -1.3955e+00, -1.4305e+00, -1.2510e+00, -5.0752e-01,  1.2130e+00,\n",
       "         -3.3784e-01, -2.1021e+00,  2.6653e-01,  1.5049e-01, -1.7894e+00,\n",
       "          4.1817e-01, -2.3390e-01,  1.2896e+00, -7.0516e-01,  1.6612e+00,\n",
       "          8.5902e-01, -4.0486e-01,  1.6848e+00,  1.3469e+00,  1.2009e+00,\n",
       "          9.7176e-01, -8.0264e-02, -1.0559e-01, -1.0489e+00,  1.0531e-01,\n",
       "         -6.2898e-01, -7.4467e-01, -5.6466e-01, -5.0776e-01,  6.2593e-01,\n",
       "         -1.4675e+00,  1.5342e+00, -2.9883e-02,  4.7549e-01, -4.2617e-01,\n",
       "         -1.5911e+00, -1.6078e-01, -3.6638e-01, -3.9732e-01, -1.1174e+00,\n",
       "         -1.0903e-01, -2.2106e-01,  1.1980e+00,  7.7866e-01,  7.1632e-01,\n",
       "          1.5420e+00, -1.3211e+00, -1.6722e-01, -2.2412e-01,  8.8964e-01,\n",
       "         -6.2998e-01,  1.7021e+00, -7.6797e-02, -1.4116e+00,  4.3858e-01,\n",
       "          8.7413e-01, -1.2284e+00, -1.8412e+00, -4.3714e-01,  5.7244e-01,\n",
       "         -1.0144e+00, -2.4161e-01,  4.6345e-01,  4.3127e-01,  1.4066e-01,\n",
       "         -4.9919e-01, -4.2034e-01, -1.6310e-01, -1.3813e+00,  1.5195e+00,\n",
       "         -1.6414e-02, -1.4476e+00, -6.4197e-01, -5.4787e-01, -1.8334e+00,\n",
       "         -2.3811e-01, -1.9942e+00, -4.3542e-01, -5.7558e-01, -1.3904e+00,\n",
       "          2.4805e-01,  2.0722e-01, -5.7644e-01, -1.6261e-01,  8.5053e-01,\n",
       "         -1.2545e-01, -5.6159e-01,  2.5422e-01,  1.8764e-01, -5.0729e-01,\n",
       "         -1.4678e+00, -1.5120e-01, -5.1539e-01,  1.2654e+00,  8.7543e-01,\n",
       "          8.0126e-01, -3.1108e-01,  1.2094e+00,  9.7609e-01, -7.9220e-01,\n",
       "          6.2272e-01,  1.4060e+00, -1.4054e+00,  1.6781e+00, -1.0384e+00,\n",
       "         -4.7168e-01, -5.7881e-01, -1.3364e+00, -1.5794e+00, -1.7438e+00,\n",
       "          1.1601e-01,  9.7697e-01],\n",
       "        [-9.4731e-01, -2.2359e+00, -8.1067e-02,  2.0432e-01,  1.4928e+00,\n",
       "         -1.5230e+00, -2.0160e+00, -1.2242e+00, -1.1357e+00, -1.4334e+00,\n",
       "         -6.5474e-01, -2.1077e-03,  9.1623e-01,  1.2269e+00, -8.6610e-04,\n",
       "         -1.8483e+00,  1.1387e+00, -2.5337e-01, -9.1826e-01, -1.8798e-01,\n",
       "         -2.6653e-01, -1.2761e+00,  4.2309e-01, -1.2282e+00, -1.0454e+00,\n",
       "          1.6150e+00,  1.6003e+00, -2.6539e-01, -4.4548e-01, -2.3533e-01,\n",
       "          5.6457e-01,  9.2762e-01,  6.1362e-01,  1.8732e+00,  4.8546e-01,\n",
       "          1.0008e+00, -1.6899e+00, -1.4723e+00, -3.3113e-01, -3.1119e-02,\n",
       "         -9.2463e-01, -5.6133e-01, -6.2230e-01,  6.4939e-01, -2.6982e-01,\n",
       "          5.7822e-01, -8.0314e-01, -1.1042e+00, -1.1166e+00, -3.3185e-01,\n",
       "         -2.5629e+00,  3.1989e-01,  4.3266e-01,  1.5543e-01, -9.1464e-01,\n",
       "          1.1972e-03, -1.3282e+00,  1.1776e+00, -1.1378e+00, -4.7235e-01,\n",
       "          2.3349e-01, -1.2854e+00, -3.2869e-01,  1.0551e+00,  1.9504e+00,\n",
       "         -4.5520e-01,  9.1685e-01, -4.7429e-01, -1.2400e+00, -6.8786e-01,\n",
       "         -2.6604e-01,  5.3623e-01,  2.7832e-01,  2.0088e+00, -1.6324e+00,\n",
       "         -4.0511e-01, -1.7823e+00,  4.9401e-01,  1.3511e+00,  1.2452e+00,\n",
       "         -2.4698e-01, -2.5422e-01, -1.3077e-01,  1.2658e+00, -1.4795e-02,\n",
       "          1.1048e+00, -2.0445e+00, -5.7493e-01, -2.1803e+00, -1.5020e-02,\n",
       "          1.3255e+00,  6.3233e-01,  1.4891e+00, -1.5201e+00,  1.3279e+00,\n",
       "         -2.7280e+00, -4.2288e-01, -8.4266e-01, -1.2089e+00,  5.8368e-01,\n",
       "         -9.2972e-01,  4.6453e-01, -8.7052e-01, -9.1236e-01,  7.0683e-01,\n",
       "         -8.7563e-01, -2.8254e-01,  3.2051e-01, -6.8166e-01, -4.0227e-01,\n",
       "          5.4716e-01,  8.7002e-02, -5.7410e-01, -1.1892e+00,  1.1089e+00,\n",
       "         -8.8904e-01,  9.2000e-01,  1.8601e-01, -5.0034e-01, -5.6545e-02,\n",
       "         -7.5617e-01,  6.3607e-01, -6.3160e-01, -4.7988e-01, -3.3305e-01,\n",
       "         -9.5816e-01,  4.1899e-01, -6.1163e-01, -2.8534e-01, -1.3565e+00,\n",
       "          6.3813e-01,  1.3511e+00],\n",
       "        [-9.4512e-01,  5.4752e-01, -4.3305e-01,  9.5732e-01, -1.0880e+00,\n",
       "          1.2397e+00, -4.6765e-01, -1.2367e+00,  4.3416e-01,  2.0542e+00,\n",
       "         -1.1236e+00, -5.4781e-01, -8.6669e-01, -6.1461e-01, -2.6577e+00,\n",
       "         -1.9636e-01, -1.7066e+00,  1.9592e+00,  3.3556e-01,  1.4113e+00,\n",
       "         -2.7149e+00, -3.4863e-01,  1.7020e+00, -5.2587e-01, -3.0204e-01,\n",
       "         -1.5251e+00, -4.4607e-01, -1.3039e+00, -9.2096e-01,  1.0140e-01,\n",
       "         -1.0677e+00, -4.2960e-01,  3.5964e-01, -1.1060e+00,  1.4096e+00,\n",
       "          1.2892e+00,  7.8831e-01, -1.0406e+00, -6.6290e-01,  2.3123e-01,\n",
       "         -1.5978e+00, -1.8153e-01, -1.9532e+00, -2.1716e+00,  1.0540e+00,\n",
       "          8.7222e-01, -5.3386e-01,  5.7605e-01, -4.1500e-01, -6.1760e-01,\n",
       "          2.8607e-01, -6.4508e-01, -3.0493e+00, -2.6013e+00,  1.2593e+00,\n",
       "         -9.6436e-01, -5.7845e-01,  9.0061e-01, -3.5545e-01,  5.1326e-01,\n",
       "         -8.2975e-01, -7.3782e-01,  5.6580e-02, -1.2761e-01, -1.8068e-01,\n",
       "         -1.3288e-01, -1.8183e+00, -1.3211e+00, -9.4805e-01,  1.9527e+00,\n",
       "         -5.4903e-01, -1.2350e-01,  8.7833e-01, -7.9396e-01,  1.2821e+00,\n",
       "          1.8721e+00,  3.7440e+00,  1.1355e+00, -1.5037e+00, -6.9937e-01,\n",
       "         -1.0439e+00,  3.0805e-01, -4.5860e-01, -1.5574e+00, -6.0480e-03,\n",
       "         -5.6781e-02, -1.1957e+00,  1.6298e-01,  1.0675e-01, -6.1092e-01,\n",
       "          8.3144e-02, -5.9142e-01,  4.0223e-01, -1.0313e+00, -1.5450e+00,\n",
       "          1.6637e-01, -2.2659e-01, -7.3246e-01, -2.1391e-01,  6.1786e-01,\n",
       "          1.2687e+00, -1.3355e+00, -1.2332e-01,  1.5081e-01,  4.5265e-01,\n",
       "         -3.1297e-01, -7.5804e-01, -3.1623e-01,  1.1020e+00,  8.2631e-01,\n",
       "          4.1594e-01,  1.2029e-01, -1.2833e+00, -5.1220e-01,  1.1183e+00,\n",
       "          8.2750e-01,  8.1880e-01, -4.9561e-01, -1.7510e+00, -1.8392e+00,\n",
       "         -3.7997e-01,  9.7664e-01,  2.9198e-03,  3.6598e-01, -1.2054e+00,\n",
       "          2.0110e+00, -3.1777e-01,  2.9864e-01, -1.2040e+00, -3.6951e-01,\n",
       "         -1.8539e+00,  1.3356e+00]])"
      ]
     },
     "metadata": {},
     "execution_count": 255
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([7, 132])"
      ]
     },
     "metadata": {},
     "execution_count": 256
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = o + u - u.mean(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([7, 132])"
      ]
     },
     "metadata": {},
     "execution_count": 258
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = torch.argmax(t, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([7])"
      ]
     },
     "metadata": {},
     "execution_count": 262
    }
   ],
   "source": [
    "gg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.3761],\n",
       "        [ 0.6314],\n",
       "        [ 1.0508],\n",
       "        [ 0.0951],\n",
       "        [ 0.2832],\n",
       "        [ 0.8200],\n",
       "        [-1.0022],\n",
       "        [-0.4210],\n",
       "        [-1.3799],\n",
       "        [-1.3393],\n",
       "        [-0.8460],\n",
       "        [ 1.0477],\n",
       "        [ 0.3984],\n",
       "        [ 0.3186],\n",
       "        [-0.0117],\n",
       "        [-1.3863],\n",
       "        [ 1.7818],\n",
       "        [-0.2634],\n",
       "        [ 0.0590],\n",
       "        [ 0.4212],\n",
       "        [-0.4254],\n",
       "        [ 1.9993],\n",
       "        [-0.6950],\n",
       "        [ 0.5532],\n",
       "        [ 0.5301],\n",
       "        [ 1.9315],\n",
       "        [-0.4562],\n",
       "        [-0.4331],\n",
       "        [-1.5994],\n",
       "        [ 0.3790],\n",
       "        [-1.6409],\n",
       "        [ 0.0164],\n",
       "        [ 0.9149],\n",
       "        [ 1.0521],\n",
       "        [ 1.4440],\n",
       "        [-1.9536],\n",
       "        [-0.1121],\n",
       "        [-1.6445],\n",
       "        [-0.2234],\n",
       "        [ 1.3067],\n",
       "        [-0.3448],\n",
       "        [-0.4653],\n",
       "        [ 0.6561],\n",
       "        [-0.3676],\n",
       "        [-2.4571],\n",
       "        [-0.2467],\n",
       "        [ 0.9734],\n",
       "        [-1.0552],\n",
       "        [-0.2301],\n",
       "        [ 0.0708],\n",
       "        [ 1.6447],\n",
       "        [ 1.4047],\n",
       "        [-0.2648],\n",
       "        [ 0.0318],\n",
       "        [ 0.6938],\n",
       "        [ 0.0110],\n",
       "        [ 1.0070],\n",
       "        [-0.0814],\n",
       "        [ 0.0718],\n",
       "        [ 0.6888],\n",
       "        [ 0.3587],\n",
       "        [ 0.5484],\n",
       "        [-1.7534],\n",
       "        [-0.8591]])"
      ]
     },
     "metadata": {},
     "execution_count": 263
    }
   ],
   "source": [
    "val = torch.randn((64,1))\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[-0.6131, -1.6083, -0.7086,  ...,  1.3295,  0.0430, -1.4160],\n",
       "         [-1.1493, -1.5214, -0.8458,  ..., -1.4012, -0.6458, -0.4141],\n",
       "         [-0.5451, -0.2409, -0.2776,  ...,  0.5319,  1.4177, -0.1636],\n",
       "         ...,\n",
       "         [-0.1787, -1.2494,  1.2123,  ...,  0.4695,  1.8131, -0.4014],\n",
       "         [-0.1482,  0.7358, -0.1270,  ..., -0.2623,  1.9428,  0.4465],\n",
       "         [ 0.9733, -2.0783, -0.3250,  ...,  1.1406, -0.6716, -0.5405]],\n",
       "\n",
       "        [[ 2.0044,  1.0991,  0.0469,  ...,  0.1628,  0.7039, -3.0131],\n",
       "         [ 0.4885, -0.0680,  0.2871,  ...,  0.7821,  0.5017, -0.8823],\n",
       "         [-0.5879,  0.3993, -1.0015,  ..., -0.0132,  0.1032,  1.5720],\n",
       "         ...,\n",
       "         [ 0.9675, -0.2651,  1.1207,  ...,  0.2892, -0.0656, -0.0147],\n",
       "         [-1.5357,  0.8144, -0.1477,  ...,  0.4607,  0.2343, -0.8858],\n",
       "         [ 0.3891, -0.7959, -0.1912,  ...,  1.9515,  1.1696, -1.7565]],\n",
       "\n",
       "        [[ 1.4549, -0.7773, -3.6935,  ..., -0.6274,  1.4550, -0.4017],\n",
       "         [-1.5494,  1.4211,  1.6072,  ...,  0.3290, -0.6618, -1.2164],\n",
       "         [-1.6586, -1.2139, -2.5339,  ..., -1.0226, -0.2450,  0.9422],\n",
       "         ...,\n",
       "         [ 0.9771,  0.6205,  1.3223,  ..., -0.3387,  0.2486, -0.2804],\n",
       "         [ 0.5073,  0.4676, -1.0692,  ..., -2.5491,  0.3604,  1.1703],\n",
       "         [ 0.4074, -0.6212, -0.6230,  ...,  0.2502, -0.3864, -0.7080]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0161,  0.7223,  1.8507,  ..., -2.1781,  1.9873, -0.6165],\n",
       "         [ 0.9973,  0.0683, -1.8276,  ..., -1.5817, -0.2962,  0.0062],\n",
       "         [-0.0633,  0.4140,  0.0278,  ..., -0.3328, -1.2274,  0.0464],\n",
       "         ...,\n",
       "         [-0.9966, -0.9046, -1.2272,  ..., -0.3418,  2.1978,  0.8346],\n",
       "         [-0.1462,  1.3720, -2.1230,  ...,  0.4892,  1.3705, -2.4573],\n",
       "         [-0.5825, -0.4402,  0.8360,  ..., -1.5464, -0.0896,  1.7991]],\n",
       "\n",
       "        [[-0.3145, -0.9487, -1.6326,  ..., -0.6566,  1.0226, -0.6461],\n",
       "         [-0.6538, -2.3143, -0.2809,  ..., -0.0789, -0.5951, -0.8023],\n",
       "         [-2.3052,  0.1024, -1.3485,  ...,  1.5432,  0.3259,  0.9578],\n",
       "         ...,\n",
       "         [ 1.3871,  1.3263,  0.5112,  ..., -1.0815, -0.0647,  1.0785],\n",
       "         [-0.9074, -0.4802, -0.7286,  ...,  0.1723, -0.2126, -1.4676],\n",
       "         [-0.8738,  0.5060,  0.0582,  ..., -1.1321,  1.9789, -0.9300]],\n",
       "\n",
       "        [[-0.8835,  2.3298, -0.4004,  ..., -0.4460,  1.3948, -0.4617],\n",
       "         [ 0.7272, -0.6333,  0.4978,  ..., -0.9315,  0.7196, -1.4384],\n",
       "         [-1.2151,  0.3512,  0.7273,  ...,  0.3226,  1.2536,  0.8345],\n",
       "         ...,\n",
       "         [-0.2895, -0.6806, -0.8670,  ...,  1.2976,  0.1178, -0.9807],\n",
       "         [ 1.9473,  0.2998, -0.9376,  ..., -0.3071, -0.8746, -0.3725],\n",
       "         [ 2.0960, -0.7271,  1.1584,  ..., -0.2694,  1.1255,  2.0747]]])"
      ]
     },
     "metadata": {},
     "execution_count": 265
    }
   ],
   "source": [
    "advs = torch.randn((64,7,132))\n",
    "advs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = value.unsqueeze(1) + advs - advs.mean(2, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([64, 7, 132])"
      ]
     },
     "metadata": {},
     "execution_count": 267
    }
   ],
   "source": [
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[119,  73, 128,  63,   8,  83, 124],\n",
       "       [  0, 130,  80,  12,   4,   3, 105],\n",
       "       [ 18, 108,  16, 131,   7,  64,  34],\n",
       "       [ 54, 118,  22,  82, 105,  13,  82],\n",
       "       [ 73,   4,  28,  48,  27, 116,  44],\n",
       "       [125,  19,  16,  51, 119,  32,  30],\n",
       "       [127,  48,  36, 103, 113,   9,  25],\n",
       "       [101,  74,  52, 103,  11,  89,  17],\n",
       "       [116,  34,   9,  21,  30,   8, 121],\n",
       "       [ 39,  54,  44, 109,  73,   0, 129],\n",
       "       [ 11,  85, 123,   5,  17,  42,   0],\n",
       "       [ 20,   6,   4,  50, 120,  67,  62],\n",
       "       [127,  87,  22,  30,  75, 129, 119],\n",
       "       [ 73,  58,  13, 116,  30,  87,   2],\n",
       "       [ 60,  80,  17,  56,  71,  43,  87],\n",
       "       [ 29, 121, 130,  61,  22, 102,  45],\n",
       "       [  8, 111,  65,  34, 107, 121,   6],\n",
       "       [ 33,  63,  47,   4,  52,  40, 114],\n",
       "       [ 78, 125, 107,   7,  63,  74,  67],\n",
       "       [ 93,  40,  75,  22,  23,  37,  22],\n",
       "       [106,  54,   7,  68, 110,  66,  59],\n",
       "       [126,  46,  17,  17, 100,  48,   5],\n",
       "       [ 49,  38,  13,  90,  81,  18,   4],\n",
       "       [ 21,  57, 104,   7,  47,  60,  64],\n",
       "       [ 46,  36, 130, 124,  30,   8,  82],\n",
       "       [ 48,  40,  67,  40,  59,  69,  67],\n",
       "       [ 70,  88,  28, 108, 122,  64,  31],\n",
       "       [ 79, 115, 102, 102,  81,   9,  39],\n",
       "       [ 82,  24,  44,  22,  42, 106,  81],\n",
       "       [ 45,   1, 105,  76,   3,  45,  73],\n",
       "       [ 29,  35,  36,  24,  26,  80,  94],\n",
       "       [109,  99,  65,  67, 119,  84,  46],\n",
       "       [  3,  92,  43,  52,  45,  12,  29],\n",
       "       [131,  37, 122,  36,  97,  80,  36],\n",
       "       [ 61,  92,  55,  45,  47,  65, 111],\n",
       "       [ 67,  76,  27,  12,  75,  83,  21],\n",
       "       [ 63,  96,  81, 101,   8, 120,   9],\n",
       "       [ 39, 125,  84,  99,  32,  92,  59],\n",
       "       [ 50,  38, 105, 106,  45,  62, 112],\n",
       "       [ 96,   1,  77, 113,  76,  64,  42],\n",
       "       [ 34,   0,  34,  62,   9,  48,  64],\n",
       "       [ 97, 121, 127,  31,   4,  70, 131],\n",
       "       [ 15,   0,  62,  21,  76,  44,  20],\n",
       "       [131,  53,   6,  90,  14,  15, 112],\n",
       "       [  2,  18, 117,  79,  73, 127,  84],\n",
       "       [120,  26,   3, 119,  77,   6,  99],\n",
       "       [ 75,  84,  63, 109,  69,  22, 106],\n",
       "       [ 45,  19,  43,   0,  32, 104,  94],\n",
       "       [ 49,  30,  64,  32, 131,   8,  34],\n",
       "       [ 37, 117,  63,   4, 114,   4,  76],\n",
       "       [107, 121, 119,  50,   0,  65,  31],\n",
       "       [ 37,   5, 125,  61,   8,  43, 107],\n",
       "       [125,  40,  82,  49,  86,  84, 100],\n",
       "       [ 28,  18,  78,  42, 119,   1,  91],\n",
       "       [119,  26, 109, 111,  95, 120,  67],\n",
       "       [ 48,  92,  24,  26,  20,  40,  75],\n",
       "       [105,  67, 102,  75, 100,  67,  13],\n",
       "       [ 86,  26, 111, 121,   8,  12,  19],\n",
       "       [ 42, 119,  45,  71, 109,  42,  46],\n",
       "       [107,  68, 117,   8,  89,  54,  13],\n",
       "       [ 30, 113, 114,  92,  65,  27,  46],\n",
       "       [ 34,  62,  30,  39,   3,   8,  28],\n",
       "       [ 97,  58,  43,  79, 109,   8,  53],\n",
       "       [ 53,  41,  34,  71,  21,  38,  65]])"
      ]
     },
     "metadata": {},
     "execution_count": 283
    }
   ],
   "source": [
    "action = np.random.randint(0,132,(64,7))\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([64, 7, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 290
    }
   ],
   "source": [
    "action = torch.tensor(action).long().reshape(64, -1,1)\n",
    "action.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([64, 7])"
      ]
     },
     "metadata": {},
     "execution_count": 296
    }
   ],
   "source": [
    "q.gather(2, action).squeeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([ 2.1277,  0.8097, -0.7525, -0.9403,  0.5868,  1.1852, -0.8028, -0.1635,\n",
       "        -1.9855,  0.1774,  0.6897, -0.0973, -0.0921,  1.2252,  0.5425, -0.0460,\n",
       "        -0.3195, -1.3524, -1.1067,  0.1798,  0.4352,  1.2553, -1.4157,  0.8198,\n",
       "        -0.3267, -1.3368,  2.1655, -0.6715,  0.3943,  0.6576, -1.1171,  1.7746,\n",
       "         0.9804, -0.2448,  0.9692,  0.6218, -0.5068, -0.1866,  0.1499,  0.6070,\n",
       "        -1.3386, -1.6255, -0.0409, -0.9370,  0.5250, -0.5374,  0.7599,  0.0478,\n",
       "        -1.4210, -0.1411, -0.7129,  1.2843, -2.7421,  0.4304,  0.5006,  0.0667,\n",
       "        -0.9927, -0.9472, -0.6609,  0.8322,  0.1069,  0.2717, -0.0605,  0.1739])"
      ]
     },
     "metadata": {},
     "execution_count": 297
    }
   ],
   "source": [
    "r = torch.randn([64])\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 2.1277],\n",
       "        [ 0.8097],\n",
       "        [-0.7525],\n",
       "        [-0.9403],\n",
       "        [ 0.5868],\n",
       "        [ 1.1852],\n",
       "        [-0.8028],\n",
       "        [-0.1635],\n",
       "        [-1.9855],\n",
       "        [ 0.1774],\n",
       "        [ 0.6897],\n",
       "        [-0.0973],\n",
       "        [-0.0921],\n",
       "        [ 1.2252],\n",
       "        [ 0.5425],\n",
       "        [-0.0460],\n",
       "        [-0.3195],\n",
       "        [-1.3524],\n",
       "        [-1.1067],\n",
       "        [ 0.1798],\n",
       "        [ 0.4352],\n",
       "        [ 1.2553],\n",
       "        [-1.4157],\n",
       "        [ 0.8198],\n",
       "        [-0.3267],\n",
       "        [-1.3368],\n",
       "        [ 2.1655],\n",
       "        [-0.6715],\n",
       "        [ 0.3943],\n",
       "        [ 0.6576],\n",
       "        [-1.1171],\n",
       "        [ 1.7746],\n",
       "        [ 0.9804],\n",
       "        [-0.2448],\n",
       "        [ 0.9692],\n",
       "        [ 0.6218],\n",
       "        [-0.5068],\n",
       "        [-0.1866],\n",
       "        [ 0.1499],\n",
       "        [ 0.6070],\n",
       "        [-1.3386],\n",
       "        [-1.6255],\n",
       "        [-0.0409],\n",
       "        [-0.9370],\n",
       "        [ 0.5250],\n",
       "        [-0.5374],\n",
       "        [ 0.7599],\n",
       "        [ 0.0478],\n",
       "        [-1.4210],\n",
       "        [-0.1411],\n",
       "        [-0.7129],\n",
       "        [ 1.2843],\n",
       "        [-2.7421],\n",
       "        [ 0.4304],\n",
       "        [ 0.5006],\n",
       "        [ 0.0667],\n",
       "        [-0.9927],\n",
       "        [-0.9472],\n",
       "        [-0.6609],\n",
       "        [ 0.8322],\n",
       "        [ 0.1069],\n",
       "        [ 0.2717],\n",
       "        [-0.0605],\n",
       "        [ 0.1739]])"
      ]
     },
     "metadata": {},
     "execution_count": 301
    }
   ],
   "source": [
    "r.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([64, 7])"
      ]
     },
     "metadata": {},
     "execution_count": 307
    }
   ],
   "source": [
    "max =  torch.argmax(q, dim=2)\n",
    "max.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([64, 7])"
      ]
     },
     "metadata": {},
     "execution_count": 334
    }
   ],
   "source": [
    "m = q.gather(2, max.unsqueeze(2)).squeeze(-1)\n",
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 332
    }
   ],
   "source": [
    "m = m.mean(1, keepdim=True)\n",
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = q.gather(2, action).squeeze(-1).mean(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 336
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 21, 101,  22, 117,  54, 101, 126],\n",
       "       [ 97,  60, 131, 124,  78,  58, 100],\n",
       "       [117, 127,  97,  71,  52, 130,  41],\n",
       "       [ 39,  40,  54,  21,  18, 131, 112],\n",
       "       [106, 127, 127,   1,  62,  14,  70],\n",
       "       [ 98,  23,  49,  82,  67,  53,  56],\n",
       "       [112,  28,  45,  20, 100,  18,  94],\n",
       "       [128,  76, 110,  48,  40,  43,  23],\n",
       "       [ 37, 104, 124,  71,  77,  54,  14],\n",
       "       [ 54, 120,  64,  54,  57,  90,  93],\n",
       "       [119,  63,  29,  65,  47,  36,  62],\n",
       "       [ 11, 131,  48,  66,  64,  71,  35],\n",
       "       [ 56,  65, 115,  68, 117, 113,  80],\n",
       "       [ 27,  19,  54,  82,  68,  57,  80],\n",
       "       [ 44,   1,  56,  36,  41,  17,  95],\n",
       "       [ 98,  54, 111,  84,  60,  58,  89],\n",
       "       [ 86,  51,  97, 123,  29,  49,  20],\n",
       "       [ 75, 117,  73,  40,  45,  81,  92],\n",
       "       [ 78,  99,  86,  87, 111, 122,  66],\n",
       "       [  4,  39,  84,   6, 127,  60,   1],\n",
       "       [ 45,  89,  81,  73,   7,  37, 119],\n",
       "       [ 85, 131,  84,  78,   7, 117,  95],\n",
       "       [ 92,  71,  10,  40, 124,  95,  24],\n",
       "       [ 80,  69,  25,   8, 124, 130, 110],\n",
       "       [119, 119,  81, 124,  94, 110,  46],\n",
       "       [107,  63,  34,  24, 125, 124,   8],\n",
       "       [ 47,  39,  37,  54,   6,  72,  21],\n",
       "       [ 60,  29, 128,  97, 101, 114, 122],\n",
       "       [ 99,  12,  65, 107,  61,  10,  17],\n",
       "       [ 81,  48, 114, 104,  46,  23,  53],\n",
       "       [ 96, 107,   3,  85, 121, 103,  48],\n",
       "       [ 39, 101, 100,   9,  52,  13,   2],\n",
       "       [ 59,  88,  22,  29,  50,  29,  71],\n",
       "       [ 33,  81,  26, 120, 114, 126,  90],\n",
       "       [  1,  14,  41, 130,  99, 130,  59],\n",
       "       [ 82,   0,  42,  39,  72,  48, 129],\n",
       "       [ 12,  59,   6, 123,  69, 126,  55],\n",
       "       [ 65,  83,  77,  72, 118,   7,  27],\n",
       "       [ 29, 100, 106, 129,  63,  86,   0],\n",
       "       [ 35,  26,  63,  25, 107,   5,  40],\n",
       "       [  5,  85,  19,  72,  83,  14,  26],\n",
       "       [ 32,  34,  57,  62, 102,  10,  22],\n",
       "       [ 74,  58,  93,  31, 128,  41,   9],\n",
       "       [ 63, 101,  26,  77,  46,  71,  58],\n",
       "       [ 56,  26,  23,  28,  48,  81,   4],\n",
       "       [ 59,  92,  14,  29,  90,  41,  92],\n",
       "       [ 67,  72,  11, 101,  33,  86,  54],\n",
       "       [ 97,  86,  79,  38, 116,  41, 123],\n",
       "       [ 64, 119,  87,  81,  62,  45,  88],\n",
       "       [  2, 128, 120,  25,  94,  63,  81],\n",
       "       [ 14,  23, 106,  44,  40,  62,  88],\n",
       "       [  3,  98,   7,  64,  70,  30, 106],\n",
       "       [ 91,  95, 126,  41,  84,  26,   3],\n",
       "       [ 33,  60,  55, 107, 116, 121,   9],\n",
       "       [ 51,  87,  12,  62,  58,  49,  22],\n",
       "       [ 59, 104, 128,  36,  66,  28,  73],\n",
       "       [ 59, 101, 105,  71,  55,  48,  54],\n",
       "       [ 72,  15, 122,  78,  46, 130,  48],\n",
       "       [ 39,  31, 129,  69, 118,  61,   8],\n",
       "       [ 23,  97,  83,  22, 114,  11,  85],\n",
       "       [ 65,  77,   9,  99,  20,  61, 102],\n",
       "       [ 87,  83,  14,   5, 114, 115,  19],\n",
       "       [ 61,   9,  55,  81, 103, 120,  65],\n",
       "       [111,  65,  57,  99, 114,  79,  86]])"
      ]
     },
     "metadata": {},
     "execution_count": 337
    }
   ],
   "source": [
    "arr = np.random.randint(0,132, (64,7))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(21, 101, 22, 117, 54, 101, 126)"
      ]
     },
     "metadata": {},
     "execution_count": 342
    }
   ],
   "source": [
    "tup = tuple(arr[0])\n",
    "tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BranchingQNetwork(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=105, out_features=128, bias=True)\n",
       "    (1): Softmax(dim=1)\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): Softmax(dim=1)\n",
       "  )\n",
       "  (value_head): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (adv_heads): ModuleList(\n",
       "    (0): Linear(in_features=128, out_features=132, bias=True)\n",
       "    (1): Linear(in_features=128, out_features=132, bias=True)\n",
       "    (2): Linear(in_features=128, out_features=132, bias=True)\n",
       "    (3): Linear(in_features=128, out_features=132, bias=True)\n",
       "    (4): Linear(in_features=128, out_features=132, bias=True)\n",
       "    (5): Linear(in_features=128, out_features=132, bias=True)\n",
       "    (6): Linear(in_features=128, out_features=132, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 358
    }
   ],
   "source": [
    "test_net = BranchingQNetwork(105, 7,132,128)\n",
    "test_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = torch.randn(105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([ 0.6068, -0.4428, -1.1576,  0.2153, -0.1393, -1.9933, -0.7204,  0.1217,\n",
       "        -1.5037, -0.2538,  1.5971,  0.4832,  1.5861, -0.1405, -1.1492, -1.8616,\n",
       "        -0.8379, -0.3530, -0.2927, -0.4449, -0.0261, -0.1967,  0.9608, -2.2096,\n",
       "        -1.3556,  0.1700,  0.3111,  1.2399,  0.4296,  0.6380,  0.6569, -0.3001,\n",
       "        -0.4208,  2.4382,  1.4229, -1.3136,  0.8232, -0.5005, -0.8583,  1.1645,\n",
       "         0.7501,  0.0166, -0.6495,  0.5600,  0.2451, -2.3889, -2.0160,  0.0750,\n",
       "         1.6876,  0.3742, -0.5670,  1.6323, -0.5089,  1.0248, -0.3840,  0.4541,\n",
       "         0.0532, -0.0627,  0.3588, -1.5633, -0.9893, -0.6159, -1.6771,  0.1770,\n",
       "         0.9134, -0.8448, -1.2995, -0.2695,  1.2415, -0.3720,  0.0207,  0.3706,\n",
       "         0.9520, -1.3827,  0.9636,  0.4412,  0.0869,  0.4826, -0.2986,  0.6677,\n",
       "        -0.4477, -0.7113,  1.6343,  0.1186, -0.5070,  1.2300, -0.4522,  1.0986,\n",
       "        -0.0648,  0.9309,  0.4840, -0.2224,  0.1758, -0.5630,  2.0756, -1.1644,\n",
       "        -0.4252, -1.9532,  1.2844, -0.2309, -0.4656,  2.0516, -0.4771,  0.3923,\n",
       "         0.1515])"
      ]
     },
     "metadata": {},
     "execution_count": 360
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-361-44b001936b3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-357-92670f1c39a8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0madvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madv_heads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m   1196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1512\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1513\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "test_net(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not list",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a1d32fd0741c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not list"
     ]
    }
   ],
   "source": [
    "list = [1,3,5,7]\n",
    "list[[2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 33.33333333333333,\n",
       " 25.0,\n",
       " 20.0,\n",
       " 33.33333333333333,\n",
       " 28.57142857142857,\n",
       " 37.5,\n",
       " 33.33333333333333]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "with open(\"rewards-20210205_230358.txt\") as f:\n",
    "    list = [float(line.rstrip()) for line in f]\n",
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f95982e3f10>]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 368.925 248.518125\" width=\"368.925pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 248.518125 \nL 368.925 248.518125 \nL 368.925 0 \nL -0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 224.64 \nL 361.725 224.64 \nL 361.725 7.2 \nL 26.925 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m4c5b0c6b9f\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.143182\" xlink:href=\"#m4c5b0c6b9f\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(38.961932 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"80.188636\" xlink:href=\"#m4c5b0c6b9f\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 1 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(77.007386 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"118.234091\" xlink:href=\"#m4c5b0c6b9f\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 2 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(115.052841 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"156.279545\" xlink:href=\"#m4c5b0c6b9f\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 3 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(153.098295 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"194.325\" xlink:href=\"#m4c5b0c6b9f\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 4 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(191.14375 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"232.370455\" xlink:href=\"#m4c5b0c6b9f\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(229.189205 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"270.415909\" xlink:href=\"#m4c5b0c6b9f\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 6 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(267.234659 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"308.461364\" xlink:href=\"#m4c5b0c6b9f\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 7 -->\n      <defs>\n       <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n      </defs>\n      <g transform=\"translate(305.280114 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-55\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"346.506818\" xlink:href=\"#m4c5b0c6b9f\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 8 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(343.325568 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m62ffc2c076\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m62ffc2c076\" y=\"214.756364\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 218.555582)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m62ffc2c076\" y=\"188.4\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 5 -->\n      <g transform=\"translate(13.5625 192.199219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m62ffc2c076\" y=\"162.043636\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 165.842855)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m62ffc2c076\" y=\"135.687273\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 15 -->\n      <g transform=\"translate(7.2 139.486491)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m62ffc2c076\" y=\"109.330909\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 113.130128)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m62ffc2c076\" y=\"82.974545\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 25 -->\n      <g transform=\"translate(7.2 86.773764)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m62ffc2c076\" y=\"56.618182\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 30 -->\n      <g transform=\"translate(7.2 60.417401)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_17\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m62ffc2c076\" y=\"30.261818\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 35 -->\n      <g transform=\"translate(7.2 34.061037)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_18\">\n    <path clip-path=\"url(#pe13a1fef28)\" d=\"M 42.143182 214.756364 \nL 80.188636 214.756364 \nL 118.234091 39.047273 \nL 156.279545 82.974545 \nL 194.325 109.330909 \nL 232.370455 39.047273 \nL 270.415909 64.148571 \nL 308.461364 17.083636 \nL 346.506818 39.047273 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 224.64 \nL 26.925 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 361.725 224.64 \nL 361.725 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 224.64 \nL 361.725 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 7.2 \nL 361.725 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pe13a1fef28\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"26.925\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.plot(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}